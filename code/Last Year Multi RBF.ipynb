{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on last year's winning submission:\n",
    "# https://github.com/openproblems-bio/neurips2021_multimodal_topmethods/tree/main/src/predict_modality/methods/Guanlab-dengkw/run\n",
    "\n",
    "import logging\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from dataclasses import dataclass\n",
    "from scipy.sparse import csc_matrix\n",
    "from prefect import flow\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "@dataclass\n",
    "class LastYearRBFExperiment(\n",
    "    utils.ExperimentParameters, \n",
    "    utils.PCAInputs, \n",
    "    utils.PCATargets, \n",
    "    utils.KFold\n",
    "    ):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = LastYearRBFExperiment(\n",
    "    MAX_ROWS_TRAIN = 25_000,\n",
    "    OUTPUT_SUBMISSION = True,\n",
    "    TECHNOLOGY = utils.multi,\n",
    "    INPUTS_PCA_DIMS = 128,\n",
    "    TARGETS_PCA_DIMS = 128,\n",
    "    K_FOLDS = 3\n",
    ")\n",
    "\n",
    "unittest = LastYearRBFExperiment(\n",
    "    MAX_ROWS_TRAIN = 1000,\n",
    "    OUTPUT_SUBMISSION = False,\n",
    "    TECHNOLOGY = utils.cite,\n",
    "    INPUTS_PCA_DIMS = 10,\n",
    "    TARGETS_PCA_DIMS = 10,\n",
    "    K_FOLDS = 3\n",
    ")\n",
    "\n",
    "np.random.seed(utils.ExperimentParameters.NP_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameter cell for papermill, do not merge or delete\n",
    "IS_TEST = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading `.sparse.npz` files...\n",
      "INFO:root:Reading `hd5 targets` files...\n"
     ]
    }
   ],
   "source": [
    "if IS_TEST:\n",
    "    EXPERIMENT = unittest\n",
    "else:\n",
    "    EXPERIMENT = submit \n",
    "datasets = utils.load_sparse_values_data(EXPERIMENT)\n",
    "inputs_train, targets_train, inputs_test = datasets.inputs_train, datasets.targets_train, datasets.inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA on all input data\n",
    "# build up a cache filename based on the experiment params\n",
    "cache_name =  utils.REDUCED_DIR / \"-\".join([\n",
    "    EXPERIMENT.TECHNOLOGY.name, \n",
    "    str(EXPERIMENT.MAX_ROWS_TRAIN), \"rows\", \n",
    "    \"submit\" if EXPERIMENT.OUTPUT_SUBMISSION else \"\",\n",
    "    \"-input_pca-\" + str(EXPERIMENT.INPUTS_PCA_DIMS) + \".pkl\"\n",
    "])\n",
    "\n",
    "input_pca_train = sp.sparse.vstack([inputs_train, inputs_test])\n",
    "logging.info('Models using the Truncated SVD to reduce the dimensionality')\n",
    "\n",
    "pca_input = TruncatedSVD(n_components=EXPERIMENT.INPUTS_PCA_DIMS)\n",
    "# TODO: float16 might be better, saw something in the forum\n",
    "pca_features = pca_input.fit_transform(input_pca_train).astype(np.float32)\n",
    "pca_train_input = pca_features[:inputs_train.shape[0]] # First len(input_train) rows are input_train\n",
    "pca_test_input = pca_features[inputs_train.shape[0]:] # Last len(input_test) rows are input_test\n",
    "assert( len(pca_train_input) + len(pca_test_input) == len(pca_features))\n",
    "\n",
    "del inputs_train\n",
    "del inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also do PCA on output (needs to be de-reduced later)\n",
    "pca_targets = TruncatedSVD(n_components=EXPERIMENT.TARGETS_PCA_DIMS)\n",
    "pca_train_targets = pca_targets.fit_transform(targets_train).astype(np.float32)\n",
    "\n",
    "del targets_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running row-wise normalization...\n"
     ]
    }
   ],
   "source": [
    "# Last year they found row-wise normalization was helpful, though they had\n",
    "# to deal with more batch effects\n",
    "logging.info('Running row-wise normalization...')\n",
    "# normalization across gene counts for a single cell.\n",
    "# Possibly useful since we only care about correlation and not magnitude\n",
    "# TODO: do we really want to normalize PCA input?\n",
    "train_norm = utils.row_wise_std_scaler(pca_train_input).astype(np.float32)\n",
    "del pca_train_input \n",
    "test_norm = utils.row_wise_std_scaler(pca_test_input).astype(np.float32)\n",
    "del pca_test_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running KRR model ...\n",
      "INFO:root:Starting k-fold loop...\n",
      "INFO:root:Fitting KRR fold 1 of 3...\n",
      "INFO:root:Score: 0.9644400591933789\n",
      "INFO:root:Fitting KRR fold 2 of 3...\n",
      "INFO:root:Score: 0.9691158634315664\n",
      "INFO:root:Fitting KRR fold 3 of 3...\n",
      "INFO:root:Score: 0.9700660943874819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ScoreSummary(scores=[Score(score=0.9644400591933789), Score(score=0.9691158634315664), Score(score=0.9700660943874819)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('Running KRR model ...')\n",
    "# TODO: research these more\n",
    "SCALE = 10\n",
    "ALPHA = .2\n",
    "logging.info('Starting k-fold loop...')\n",
    "\n",
    "kf = KFold(n_splits=EXPERIMENT.K_FOLDS)\n",
    "\n",
    "kernel = RBF(length_scale = SCALE)\n",
    "krr = KernelRidge(alpha=ALPHA, kernel=kernel)  # type: ignore\n",
    "\n",
    "def fit_and_score(*,\n",
    "    fold_index: int,\n",
    "    train_indices: np.ndarray,\n",
    "    test_indices: np.ndarray,\n",
    "    pca_targets,\n",
    "    ) -> utils.Score:\n",
    "    \"\"\"\n",
    "    performs fit and returns score\n",
    "    \"\"\"\n",
    "    logging.info(\n",
    "        f'Fitting KRR fold {fold_index + 1} of {EXPERIMENT.K_FOLDS}...'\n",
    "    )\n",
    "    krr.fit(\n",
    "        train_norm[train_indices], \n",
    "        pca_train_targets[train_indices]\n",
    "    )\n",
    "    # TODO: review pca de-reduction\n",
    "    Y_hat = krr.predict(train_norm[test_indices]) @ pca_targets.components_\n",
    "    Y = pca_train_targets[test_indices] @ pca_targets.components_\n",
    "    score = utils.correlation_score(Y, Y_hat)\n",
    "    logging.info(f\"Score: {score}\")\n",
    "    return utils.Score(score=score)\n",
    "\n",
    "scores = []\n",
    "for fold_index, (train_index, test_index) in enumerate(kf.split(train_norm)):\n",
    "    score = fit_and_score(\n",
    "        fold_index=fold_index, \n",
    "        train_indices=train_index,\n",
    "        test_indices=test_index,\n",
    "        pca_targets = pca_targets,\n",
    "    )\n",
    "    scores.append(score)\n",
    "\n",
    "# TODO: require clean history (git), write outputs to file\n",
    "utils.ScoreSummary(scores=scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading indices...\n",
      "INFO:root:Loading evaluation ids...\n",
      "INFO:root:Final step: fill empty submission df...\n"
     ]
    }
   ],
   "source": [
    "# TODO: extract to utils method\n",
    "if EXPERIMENT.OUTPUT_SUBMISSION: \n",
    "    OTHER_FILENAME = 'cite_rbf_with_multi_linear'\n",
    "    OTHER_SUBMISSION_PATH = utils.OUTPUT_DIR / f'{OTHER_FILENAME}.csv' \n",
    "    # fit model on downsampled data\n",
    "    krr.fit(train_norm, pca_train_targets)\n",
    "    # predict on full submission inputs\n",
    "    Y_hat = krr.predict(test_norm) @ pca_targets.components_\n",
    "    \n",
    "    # Format this experiment for submission\n",
    "    this_submission = utils.format_submission(\n",
    "        Y_hat, EXPERIMENT.TECHNOLOGY\n",
    "    )\n",
    "    # Load other submission which includes predictions for alternate tech \n",
    "    other_submission = pd.read_csv(OTHER_SUBMISSION_PATH, index_col=0)\n",
    "    \n",
    "    # drop multi-index to align with other submission\n",
    "    reindexed_submission_this = pd.DataFrame(\n",
    "        this_submission.reset_index(drop=True)\n",
    "    )\n",
    "    # Merge with separate predictions for other technology \n",
    "    merged = (reindexed_submission_this['target']\n",
    "              .fillna(\n",
    "                  other_submission[\n",
    "                      reindexed_submission_this['target'].isna()]['target']\n",
    "              )\n",
    "    )\n",
    "    # put into dataframe with proper column names\n",
    "    formatted_submission = pd.DataFrame(merged, columns=['target'])\n",
    "    formatted_submission.index.name = \"row_id\"\n",
    "    utils.test_valid_submission(formatted_submission)\n",
    "    # write full predictions to csv\n",
    "    formatted_submission.to_csv(\n",
    "        utils.OUTPUT_DIR / f\"{EXPERIMENT.TECHNOLOGY.name}_rbf_with_{OTHER_FILENAME}.csv\")\n",
    "else:\n",
    "    logging.info(\"======Test Passed!======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle competitions submit -c open-problems-multimodal -f submission.csv -m \"EXPERIMENT.__str__()\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffd6c8928b0ee1ff35d95e1a002ba83d6fc6c953861d0ac4f834d9a76673592c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
