{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on last year's winning submission:\n",
    "# https://github.com/openproblems-bio/neurips2021_multimodal_topmethods/tree/main/src/predict_modality/methods/Guanlab-dengkw/run\n",
    "\n",
    "import logging\n",
    "import utils\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Whole notebooks fits in about 1min for 10k rows. \n",
    "- 100k failed with an error: `Canceled future for execute_request message before replies were done`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentParameters:\n",
    "    MAX_ROWS = 10_000\n",
    "    REPO: utils.ExperimentRepository = utils.cite\n",
    "    INPUT_PCA_DIMS = 128\n",
    "    OUTPUT_PCA_DIMS = 128\n",
    "    K_FOLDS = 3\n",
    "    NP_RANDOM_SEED = 1000\n",
    "\n",
    "\n",
    "np.random.seed(ExperimentParameters.NP_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading `h5ad` files...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'ExperimentParameters' has no attribute 'train_inputs_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReading `h5ad` files...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# TODO: extract to method with params  (sparse/dense, technology)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m input_train\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_hdf(\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mExperimentParameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_inputs_path\u001b[49m, \n\u001b[1;32m      5\u001b[0m     start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m      6\u001b[0m     stop\u001b[38;5;241m=\u001b[39mExperimentParameters\u001b[38;5;241m.\u001b[39mMAX_ROWS\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m output_train\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_hdf(\n\u001b[1;32m      9\u001b[0m     ExperimentParameters\u001b[38;5;241m.\u001b[39mtrain_targets_path,\n\u001b[1;32m     10\u001b[0m     start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m     11\u001b[0m     stop\u001b[38;5;241m=\u001b[39mExperimentParameters\u001b[38;5;241m.\u001b[39mMAX_ROWS\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m input_test\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_hdf(\n\u001b[1;32m     14\u001b[0m     ExperimentParameters\u001b[38;5;241m.\u001b[39mtest_inputs_path, \n\u001b[1;32m     15\u001b[0m     start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m     16\u001b[0m     stop\u001b[38;5;241m=\u001b[39mExperimentParameters\u001b[38;5;241m.\u001b[39mMAX_ROWS\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ExperimentParameters' has no attribute 'train_inputs_path'"
     ]
    }
   ],
   "source": [
    "logging.info('Reading `h5ad` files...')\n",
    "# TODO: extract to method with params  (sparse/dense, technology)\n",
    "input_train= pd.read_hdf(\n",
    "    ExperimentParameters.train_inputs_path, \n",
    "    start=0, \n",
    "    stop=ExperimentParameters.MAX_ROWS\n",
    ")\n",
    "output_train= pd.read_hdf(\n",
    "    ExperimentParameters.train_targets_path,\n",
    "    start=0, \n",
    "    stop=ExperimentParameters.MAX_ROWS\n",
    ")\n",
    "input_test= pd.read_hdf(\n",
    "    ExperimentParameters.test_inputs_path, \n",
    "    start=0, \n",
    "    stop=ExperimentParameters.MAX_ROWS\n",
    ")\n",
    "\n",
    "pred_dim_x = input_test.shape[0]\n",
    "pred_dim_y = output_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Do PCA on all input data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m input_pca_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[0;32m----> 3\u001b[0m     [\u001b[43minput_train\u001b[49m, input_test],\n\u001b[1;32m      4\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModels using the Truncated SVD to reduce the dimension\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m pca_input \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39mExperimentParameters\u001b[38;5;241m.\u001b[39mINPUT_PCA_DIMS)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Do PCA on all input data\n",
    "input_pca_train = pd.concat(\n",
    "    [input_train, input_test],\n",
    "    axis=0,  # type: ignore\n",
    ")\n",
    "\n",
    "logging.info('Models using the Truncated SVD to reduce the dimension')\n",
    "\n",
    "pca_input = TruncatedSVD(n_components=ExperimentParameters.INPUT_PCA_DIMS)\n",
    "# TODO: float16 might be better, saw something in the forum\n",
    "pca_features = pca_input.fit_transform(input_pca_train).astype(np.float32)\n",
    "pca_train_input = pca_features[:len(input_train)] # First len(input_train) rows are input_train\n",
    "pca_test_input = pca_features[len(input_train):] # Last len(input_test) rows are input_test\n",
    "assert( len(pca_train_input) + len(pca_test_input) == len(pca_features))\n",
    "\n",
    "del input_train\n",
    "del input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also do PCA on output (needs to be de-reduced later)\n",
    "pca_output = TruncatedSVD(n_components=ExperimentParameters.OUTPUT_PCA_DIMS)\n",
    "pca_train_output = pca_output.fit_transform(output_train).astype(np.float32)\n",
    "\n",
    "del output_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running row-wise normalization...\n"
     ]
    }
   ],
   "source": [
    "# Last year they found row-wise normalization was helpful, though they had\n",
    "# to deal with more batch effects\n",
    "def row_wise_std_scaler(M):\n",
    "    \"\"\" \n",
    "    Standard scale values by row. \n",
    "    Sklearn StandardScaler has now row-wise option\n",
    "    \"\"\"\n",
    "    std = np.std(M, axis=1).reshape(-1, 1)\n",
    "    # Make any zero std 1 to avoid numerical problems\n",
    "    std[std == 0] = 1\n",
    "    mean = np.mean(M, axis=1).reshape(-1, 1)\n",
    "    return (M - mean) / std\n",
    "\n",
    "logging.info('Running row-wise normalization...')\n",
    "# normalization across gene counts for a single cell.\n",
    "# Possibly useful since we only care about correlation and not magnitude\n",
    "# TODO: do we really want to normalize PCA input?\n",
    "train_norm = row_wise_std_scaler(pca_train_input).astype(np.float32)\n",
    "del pca_train_input \n",
    "test_norm = row_wise_std_scaler(pca_test_input).astype(np.float32)\n",
    "del pca_test_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running KRR model ...\n",
      "INFO:root:Starting k-fold loop...\n",
      "INFO:root:Fitting KRR fold 0 of 3...\n",
      "INFO:root:Score: 0.8908717086652675\n",
      "INFO:root:Fitting KRR fold 1 of 3...\n",
      "INFO:root:Score: 0.8912362154462354\n",
      "INFO:root:Fitting KRR fold 2 of 3...\n",
      "INFO:root:Score: 0.8881603906429922\n"
     ]
    }
   ],
   "source": [
    "logging.info('Running KRR model ...')\n",
    "# TODO: research these more\n",
    "SCALE = 10\n",
    "ALPHA = .2\n",
    "logging.info('Starting k-fold loop...')\n",
    "\n",
    "kf = KFold(n_splits=ExperimentParameters.K_FOLDS)\n",
    "\n",
    "def report_score(score):\n",
    "    logging.info(f\"Score: {score}\")\n",
    "    # TODO: add results writing\n",
    "    \n",
    "for fold_index, (train_index, test_index) in enumerate(kf.split(train_norm)):\n",
    "    kernel = RBF(length_scale = SCALE)\n",
    "    krr = KernelRidge(alpha=ALPHA, kernel=kernel)  # type: ignore\n",
    "    logging.info(f'Fitting KRR fold {fold_index} of {ExperimentParameters.K_FOLDS}...')\n",
    "    krr.fit(train_norm[train_index], pca_train_output[train_index])\n",
    "    # TODO: review pca de-reduction\n",
    "    Y_hat = krr.predict(train_norm[test_index]) @ pca_output.components_\n",
    "    Y = pca_train_output[test_index] @ pca_output.components_\n",
    "    score = utils.correlation_score(Y, Y_hat)\n",
    "    report_score(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('singlecell-kaggle-3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fde1271e143971705c129d5d46205877bec13a88aaeddeee17f452b3bebf926"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
