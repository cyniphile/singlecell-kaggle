{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on last year's winning submission:\n",
    "# https://github.com/openproblems-bio/neurips2021_multimodal_topmethods/tree/main/src/predict_modality/methods/Guanlab-dengkw/run\n",
    "\n",
    "import logging\n",
    "import utils\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Whole notebooks fits in about 1min for 10k rows. \n",
    "- 100k failed with an error: `Canceled future for execute_request message before replies were done`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading `h5ad` files...\n"
     ]
    }
   ],
   "source": [
    "# TODO: look up viash:  https://viash.io/\n",
    "par = {\n",
    "    'input_train': '../data/original/train_cite_inputs.h5',\n",
    "    'output_train': '../data/original/train_cite_targets.h5',\n",
    "    'input_test': '../data/original/test_cite_inputs.h5',\n",
    "}\n",
    "\n",
    "LIMIT = 100000\n",
    "\n",
    "logging.info('Reading `h5ad` files...')\n",
    "input_train= pd.read_hdf(par['input_train'], start=0, stop=LIMIT)\n",
    "output_train= pd.read_hdf(par['output_train'], start=0, stop=LIMIT)\n",
    "input_test= pd.read_hdf(par['input_test'], start=0, stop=LIMIT)\n",
    "\n",
    "pred_dim_x = input_test.shape[0]\n",
    "pred_dim_y = output_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Models using the Truncated SVD to reduce the dimension\n"
     ]
    }
   ],
   "source": [
    "input_pca_train = pd.concat(\n",
    "    [input_train, input_test],\n",
    "    axis=0,  # type: ignore\n",
    ")\n",
    "\n",
    "# Do PCA on all input data\n",
    "logging.info('Models using the Truncated SVD to reduce the dimension')\n",
    "\n",
    "PCA_COMPONENTS_INPUT = 128\n",
    "pca_input = TruncatedSVD(n_components=PCA_COMPONENTS_INPUT)\n",
    "pca_features = pca_input.fit_transform(input_pca_train).astype(np.float32)\n",
    "pca_train_input = pca_features[:len(input_train)] # First len(input_train) rows are input_train\n",
    "pca_test_input = pca_features[len(input_train):] # Last len(input_test) rows are input_test\n",
    "assert( len(pca_train_input) + len(pca_test_input) == len(pca_features))\n",
    "\n",
    "del input_train\n",
    "del input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_COMPONENTS_OUTPUT = 128\n",
    "pca_output = TruncatedSVD(n_components=PCA_COMPONENTS_OUTPUT)\n",
    "pca_train_output = pca_output.fit_transform(output_train).astype(np.float32)\n",
    "\n",
    "del output_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running row-wise normalization...\n"
     ]
    }
   ],
   "source": [
    "def row_wise_std_scaler(M):\n",
    "    std = np.std(M, axis=1).reshape(-1, 1)\n",
    "    # Make any zero std 1 to avoid numerical problems\n",
    "    std[std == 0] = 1\n",
    "    mean = np.mean(M, axis=1).reshape(-1, 1)\n",
    "    return (M - mean) / std\n",
    "\n",
    "logging.info('Running row-wise normalization...')\n",
    "# normalization across gene counts for a single cell.\n",
    "# Possibly useful since we only care about correlation and not magnitude\n",
    "# TODO: do we really want to normalize PCA input?\n",
    "train_norm = row_wise_std_scaler(pca_train_input).astype(np.float32)\n",
    "del pca_train_input \n",
    "test_norm = row_wise_std_scaler(pca_test_input).astype(np.float32)\n",
    "del pca_test_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running KRR model ...\n",
      "INFO:root:Fitting KRR ... \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi Ã¨ verificato un arresto anomalo del kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. Esaminare il codice nelle celle per identificare una possibile causa dell'errore. Per altre informazioni, fare clic su <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a>. Per altri dettagli, vedere Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "logging.info('Running KRR model ...')\n",
    "y_pred = np.zeros((pred_dim_x, pred_dim_y), dtype=np.float32)\n",
    "np.random.seed(1000)\n",
    "\n",
    "# TODO: research these more\n",
    "SCALE = 10\n",
    "ALPHA = .2\n",
    "\n",
    "kernel = RBF(length_scale = SCALE)\n",
    "krr = KernelRidge(alpha=ALPHA, kernel=kernel)  # type: ignore\n",
    "logging.info('Fitting KRR ... ')\n",
    "krr.fit(train_norm, pca_train_output)\n",
    "# TODO: review pca de-reduction\n",
    "y_pred += (krr.predict(test_norm) @ pca_output.components_)\n",
    "\n",
    "# Store as sparse matrix to be efficient. Note that this might require\n",
    "# different classifiers/embedders before-hand. Not every class is able\n",
    "# to support such data structures.\n",
    "y_pred = csc_matrix(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffd6c8928b0ee1ff35d95e1a002ba83d6fc6c953861d0ac4f834d9a76673592c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
