{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on last year's winning submission:\n",
    "# https://github.com/openproblems-bio/neurips2021_multimodal_topmethods/tree/main/src/predict_modality/methods/Guanlab-dengkw/run\n",
    "\n",
    "import logging\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Whole notebooks fits in about 1min for 10k rows. \n",
    "- 50k failed with an error: `Canceled future for execute_request message before replies were done`\n",
    "- 100k failed with an error: `Canceled future for execute_request message before replies were done`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LastYearRBFExperiment(\n",
    "    utils.ExperimentParameters, \n",
    "    utils.PCAInputs, \n",
    "    utils.PCATargets, \n",
    "    utils.KFold\n",
    "    ):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = LastYearRBFExperiment(\n",
    "    MAX_ROWS_TRAIN = 50_000,\n",
    "    OUTPUT_SUBMISSION = True,\n",
    "    TECHNOLOGY = utils.cite,\n",
    "    INPUTS_PCA_DIMS = 128,\n",
    "    TARGETS_PCA_DIMS = 128,\n",
    "    K_FOLDS = 3\n",
    ")\n",
    "\n",
    "unittest = LastYearRBFExperiment(\n",
    "    MAX_ROWS_TRAIN = 1000,\n",
    "    OUTPUT_SUBMISSION = False,\n",
    "    TECHNOLOGY = utils.cite,\n",
    "    INPUTS_PCA_DIMS = 10,\n",
    "    TARGETS_PCA_DIMS = 10,\n",
    "    K_FOLDS = 3\n",
    ")\n",
    "\n",
    "np.random.seed(utils.ExperimentParameters.NP_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameter cell for papermill, do not merge or delete\n",
    "IS_TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading `h5ad` files...\n",
      "INFO:root:Reading `h5ad` files...\n"
     ]
    }
   ],
   "source": [
    "if IS_TEST:\n",
    "    EXPERIMENT = unittest\n",
    "else:\n",
    "    EXPERIMENT = submit \n",
    "logging.info('Reading `h5ad` files...')\n",
    "datasets = utils.load_hdf_data(EXPERIMENT)\n",
    "inputs_train, targets_train, inputs_test = datasets.inputs_train, datasets.targets_train, datasets.inputs_test\n",
    "pred_dim_x = inputs_test.shape[0]\n",
    "pred_dim_y = targets_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Do PCA on all input data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m input_pca_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(\n\u001b[0;32m----> 3\u001b[0m     [inputs_train\u001b[39m.\u001b[39mvalues, inputs_test\u001b[39m.\u001b[39mvalues],\n\u001b[1;32m      4\u001b[0m     axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mModels using the Truncated SVD to reduce the dimension\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m pca_input \u001b[39m=\u001b[39m TruncatedSVD(n_components\u001b[39m=\u001b[39mEXPERIMENT\u001b[39m.\u001b[39mINPUTS_PCA_DIMS)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Do PCA on all input data\n",
    "input_pca_train = np.concatenate(\n",
    "    [inputs_train.values, inputs_test.values],\n",
    "    axis=0,  # type: ignore\n",
    ")\n",
    "\n",
    "logging.info('Models using the Truncated SVD to reduce the dimension')\n",
    "\n",
    "pca_input = TruncatedSVD(n_components=EXPERIMENT.INPUTS_PCA_DIMS)\n",
    "# TODO: float16 might be better, saw something in the forum\n",
    "pca_features = pca_input.fit_transform(input_pca_train).astype(np.float32)\n",
    "pca_train_input = pca_features[:inputs_train.shape[0]] # First len(input_train) rows are input_train\n",
    "pca_test_input = pca_features[inputs_train.shape[0]:] # Last len(input_test) rows are input_test\n",
    "assert( len(pca_train_input) + len(pca_test_input) == len(pca_features))\n",
    "\n",
    "del inputs_train\n",
    "del inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also do PCA on output (needs to be de-reduced later)\n",
    "pca_targets = TruncatedSVD(n_components=EXPERIMENT.TARGETS_PCA_DIMS)\n",
    "pca_train_targets = pca_targets.fit_transform(targets_train).astype(np.float32)\n",
    "\n",
    "del targets_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running row-wise normalization...\n"
     ]
    }
   ],
   "source": [
    "# Last year they found row-wise normalization was helpful, though they had\n",
    "# to deal with more batch effects\n",
    "logging.info('Running row-wise normalization...')\n",
    "# normalization across gene counts for a single cell.\n",
    "# Possibly useful since we only care about correlation and not magnitude\n",
    "# TODO: do we really want to normalize PCA input?\n",
    "train_norm = utils.row_wise_std_scaler(pca_train_input).astype(np.float32)\n",
    "del pca_train_input \n",
    "test_norm = utils.row_wise_std_scaler(pca_test_input).astype(np.float32)\n",
    "del pca_test_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running KRR model ...\n",
      "INFO:root:Starting k-fold loop...\n",
      "INFO:root:Fitting KRR fold 1 of 3...\n",
      "INFO:root:Score: 0.8949106658140031\n",
      "INFO:root:Fitting KRR fold 2 of 3...\n",
      "INFO:root:Score: 0.8970165402257735\n",
      "INFO:root:Fitting KRR fold 3 of 3...\n",
      "INFO:root:Score: 0.8962209142114527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ScoreSummary(scores=[Score(score=0.8949106658140031), Score(score=0.8970165402257735), Score(score=0.8962209142114527)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info('Running KRR model ...')\n",
    "# TODO: research these more\n",
    "SCALE = 10\n",
    "ALPHA = .2\n",
    "logging.info('Starting k-fold loop...')\n",
    "\n",
    "kf = KFold(n_splits=EXPERIMENT.K_FOLDS)\n",
    "\n",
    "\n",
    "kernel = RBF(length_scale = SCALE)\n",
    "krr = KernelRidge(alpha=ALPHA, kernel=kernel)  # type: ignore\n",
    "\n",
    "def fit_and_score(*,\n",
    "    fold_index: int,\n",
    "    train_indices: np.ndarray,\n",
    "    test_indices: np.ndarray,\n",
    "    pca_targets,\n",
    "    ) -> utils.Score:\n",
    "    \"\"\"\n",
    "    performs fit and returns score\n",
    "    \"\"\"\n",
    "    logging.info(\n",
    "        f'Fitting KRR fold {fold_index + 1} of {EXPERIMENT.K_FOLDS}...'\n",
    "    )\n",
    "    krr.fit(\n",
    "        train_norm[train_indices], \n",
    "        pca_train_targets[train_indices]\n",
    "    )\n",
    "    # TODO: review pca de-reduction\n",
    "    Y_hat = krr.predict(train_norm[test_indices]) @ pca_targets.components_\n",
    "    Y = pca_train_targets[test_indices] @ pca_targets.components_\n",
    "    score = utils.correlation_score(Y, Y_hat)\n",
    "    logging.info(f\"Score: {score}\")\n",
    "    return utils.Score(score=score)\n",
    "\n",
    "scores = []\n",
    "for fold_index, (train_index, test_index) in enumerate(kf.split(train_norm)):\n",
    "    score = fit_and_score(\n",
    "        fold_index=fold_index, \n",
    "        train_indices=train_index,\n",
    "        test_indices=test_index,\n",
    "        pca_targets = pca_targets,\n",
    "    )\n",
    "    scores.append(score)\n",
    "\n",
    "# TODO: require clean history (git), write outputs to file\n",
    "scores = utils.ScoreSummary(scores=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi Ã¨ verificato un arresto anomalo del kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. Esaminare il codice nelle celle per identificare una possibile causa dell'errore. Per altre informazioni, fare clic su <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a>. Per altri dettagli, vedere Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# TODO: extract to utils method\n",
    "if EXPERIMENT.OUTPUT_SUBMISSION: \n",
    "    # fit model on downsampled data\n",
    "    krr.fit(train_norm, pca_train_targets)\n",
    "\n",
    "    # predict on full submission inputs\n",
    "    Y_hat = krr.predict(test_norm) @ pca_targets.components_\n",
    "\n",
    "    submission_cite = utils.format_submission(Y_hat, utils.cite)\n",
    "    # Load old submission which includes multiome tech predictions\n",
    "    multi_submission = pd.read_csv(\n",
    "        utils.OUTPUT_DIR / \"full_64_reduced_linreg.csv\",\n",
    "        index_col=0\n",
    "    )\n",
    "    # drop multi-index to align with other submission\n",
    "    reindexed_submission_cite = pd.DataFrame(submission_cite.reset_index(drop=True))\n",
    "\n",
    "    # Merge with separate predictions for other technology \n",
    "    merged = reindexed_submission_cite['target'].fillna(multi_submission[reindexed_submission_cite['target'].isna()]['target'])\n",
    "    # put into dataframe with proper column names\n",
    "    formatted_submission = pd.DataFrame(merged, columns=['target'])\n",
    "    formatted_submission.index.name = \"row_id\"\n",
    "    utils.test_valid_submission(formatted_submission)\n",
    "    # write full predictions to csv\n",
    "    formatted_submission.to_csv(utils.OUTPUT_DIR / \"cite_rbf_with_multi_linear.csv\")\n",
    "else:\n",
    "    assert sum([s.score for s in scores.scores]) / EXPERIMENT.K_FOLDS > .9\n",
    "    logging.info(\"======Test Passed!======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle competitions submit -c open-problems-multimodal -f submission.csv -m \"EXPERIMENT.__str__()\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffd6c8928b0ee1ff35d95e1a002ba83d6fc6c953861d0ac4f834d9a76673592c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
